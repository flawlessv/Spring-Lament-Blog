# 向量索引系统技术文档

## 系统概述

这个系统实现了基于向量检索的 RAG 能力，用来对博客文章进行语义索引和智能检索。简单说就是：把文章切分成小块，转换成向量存起来，用户提问时找到相关的块，然后让 AI 基于这些块生成回答。

### 技术选型

- **Embedding 模型**: Ollama (nomic-embed-text) - 本地运行，完全免费
- **向量数据库**: ChromaDB - 开源轻量，性能不错
- **语言模型**: Kimi (Moonshot AI) - 中文能力强，免费额度够用

### 工作流程

```
文章内容
    ↓
语义分块 - 按段落/句子切分，保持语义完整
    ↓
生成向量 - 用 Ollama 把每个块转成向量
    ↓
存储向量 - 存到 ChromaDB，带上文章信息
    ↓
检索查询 - 用户提问时，找最相关的块
    ↓
生成回答 - 用 Kimi 基于检索到的块生成回答
```

---

## 核心设计

### 1. 语义感知的分块策略

最开始我试过简单的按字符数硬切，结果发现很多问题：

- 句子被截断，读起来不完整
- 段落被分割，逻辑断了
- 检索时匹配到不完整的片段，回答质量差

后来改成了三级分块策略：

**第一级：按段落分割**

- 用 `\n\n+` 正则匹配段落
- 每个段落作为独立的语义单元，保持文章结构

**第二级：按句子分割**

- 如果段落太长，按 `。！？\n` 分割成句子
- 保证句子完整性，不会在句子中间切断

**第三级：严格控制大小**

- 在语义分割的同时，严格控制块大小
- 避免后续硬切破坏语义

这样分块后，检索时匹配到的都是完整的语义片段，回答质量明显提升。

### 2. 重叠策略

相邻块之间如果没有重叠，跨块的信息可能会丢失。比如一个概念在前一个块的末尾和后一个块的开头都有提到，没有重叠的话检索时可能匹配不到。

我的做法是默认重叠 50 字符。保存当前块时，保留末尾的 50 个字符，下一个块从这 50 个字符开始。这样边界信息不会丢失，块之间的上下文也更连贯。

### 3. 双重限制保护

Ollama 对单次输入有 800 字符的硬限制，但仅按 token 数限制可能导致字符数超限。所以我做了双重检查：

- **Token 限制**：估算 token 数，控制语义长度（默认 300 tokens）
- **字符限制**：硬限制字符数，严格遵守 800 字符限制

两个限制都要满足，避免 embedding 生成失败。

### 4. 多向量支持

如果某个块超过 800 字符，Ollama 无法处理。如果求平均会丢失信息，所以我改成硬切为多个子块，每个子块生成独立的 embedding，单独存储。这样所有子块的语义信息都保留了，检索时也能匹配到。

### 5. 性能优化

- **批量处理**：支持批量索引所有文章，自动跳过已索引的
- **重试机制**：Embedding 生成失败自动重试，最多 3 次
- **限流保护**：每处理 5 个块后等待 100ms，避免 Ollama 过载
- **超时控制**：30 秒超时，避免长时间等待

---

## 实现中的难点

### 难点 1: 语义分块 vs 硬限制的平衡

语义分块希望保持完整性，可能产生较大的块，但 Ollama 有 800 字符的硬限制。我的解决方案是：

1. 在语义分块阶段就严格控制大小
2. 优先按段落/句子分割，保持语义完整性
3. 实在不行才硬切，这是最后手段

代码里做了双重检查：

```typescript
// 既检查 token 数，也检查字符数
const chunkTokens = estimateTokens(currentChunk);
const chunkChars = currentChunk.length;

if (chunkTokens > maxTokens || chunkChars > maxChars) {
  // 需要进一步分割
  splitChunk(currentChunk);
}
```

### 难点 2: 长文本的向量生成策略

如果块超过 800 字符，Ollama 无法处理。求平均会丢失信息，所以我改成硬切为多个子块，每个子块生成独立的 embedding，单独存储。

```typescript
// 如果超过 800 字符，返回多个向量
if (t.length > MAX_CHUNK_SIZE) {
  const chunks = hardSplit(t);
  for (const chunk of chunks) {
    const embedding = await getEmbedding(chunk);
    embeddings.push(embedding); // 返回多个向量
  }
}
```

### 难点 3: Token 估算的准确性

中英文混合文本的 token 估算不准确，估算偏差可能导致块大小控制失效。我的做法是：

- 中文按字符数估算（1 字符 ≈ 1.5 tokens）
- 英文按单词数估算（1 单词 ≈ 1.3 tokens）
- 允许一定误差，但双重检查字符数确保不超过 800

```typescript
function estimateTokens(text: string): number {
  const chineseChars = (text.match(/[\u4e00-\u9fa5]/g) || []).length;
  const englishWords = text
    .split(/\s+/)
    .filter((w) => /[a-zA-Z]/.test(w)).length;
  return Math.ceil(chineseChars * 1.5 + englishWords * 1.3);
}
```

### 难点 4: 子块的管理和检索

一个语义块可能对应多个向量（子块），需要正确关联和检索。我用 `chunkIndex_subChunkIndex` 作为向量 ID，在 metadata 中标记 `isSubChunk: true`，检索时可以通过 `chunkIndex` 关联所有子块。

```typescript
// 为子块创建向量记录
vectors.push({
  id: `${postId}_${chunk.index}_${j}`,
  embedding: chunkEmbeddings[j],
  metadata: {
    chunkIndex: chunk.index,
    subChunkIndex: j,
    isSubChunk: true,
    // ...
  },
});
```

---

## 整体流程

### 索引流程（Indexing）

```
1. 获取文章
   ↓
2. 检查是否已索引（避免重复索引）
   ↓
3. 语义分块 (chunkPost)
   - 按段落分割
   - 按句子分割（如需要）
   - 严格控制大小（≤800字符）
   ↓
4. 生成 Embedding (ollamaEmbed)
   - 为每个块生成向量
   - 如果块超过800字符，生成多个向量
   - 重试机制（最多3次）
   ↓
5. 构建向量数据
   - 为每个向量创建 metadata
   - 包含文章信息、块索引等
   ↓
6. 存储到 ChromaDB
   - 向量 + 元数据 + 原文
   ↓
7. 更新索引记录
   - 记录文章ID、块数量等
```

### 检索流程（Retrieval）

```
1. 用户提问
   ↓
2. 生成查询向量 (embed(question))
   ↓
3. 向量相似度搜索 (ChromaDB)
   - 找到最相关的 K 个块
   - 返回相似度分数
   ↓
4. 过滤和排序
   - 按相似度排序
   - 可选：按文章、分类过滤
   ↓
5. 构建上下文
   - 组合多个相关块
   - 添加文章元数据
   ↓
6. 生成回答 (Kimi)
   - 基于检索到的上下文
   - 流式返回结果
```

---

## 分块策略详解

分块流程大致是这样的：

1. 先按段落分割（`\n\n+`）
2. 遍历每个段落，如果段落太长就按句子分割（`。！？\n`）
3. 控制块大小，超过限制就保存当前块，保留重叠

关键参数：

- `maxTokens`: 300（Token 数限制，控制语义长度）
- `maxChars`: 800（字符数硬限制，遵守 Ollama 限制）
- `overlap`: 50（块之间的重叠字符数）

举个例子，输入文章：

```
段落1：这是第一段内容，包含多个句子。每个句子都有意义。

段落2：这是第二段，内容较长。包含很多信息。需要仔细处理。确保完整性。

段落3：短段落。
```

分块结果：

```
块0: "段落1：这是第一段内容，包含多个句子。每个句子都有意义。"
块1: "段落2：这是第二段，内容较长。包含很多信息。需要仔细处理。确保完整性。"
块2: "段落3：短段落。"
```

---

## Embedding 生成策略

处理逻辑很简单：

- 如果文本块 ≤ 800 字符，直接生成 embedding
- 如果 > 800 字符，硬切分块，每个子块生成独立的 embedding

重试机制：

- 最大重试 3 次
- 重试间隔 1 秒
- 超时 30 秒
- 失败后抛出错误，记录日志

性能优化：

- 限流：每处理 5 个块后等待 100ms，避免 Ollama 过载
- 串行处理，不并发
- 自动重试，提高成功率

---

## 向量存储与检索

向量数据结构：

```typescript
{
  id: "postId_chunkIndex" | "postId_chunkIndex_subChunkIndex",
  embedding: number[], // 768 维向量（nomic-embed-text）
  metadata: {
    postId: string,
    chunkIndex: number,
    subChunkIndex?: number, // 仅子块有
    isSubChunk?: boolean,   // 仅子块有
    title: string,
    slug: string,
    category: string,
    tags: string,
  },
  document: string, // 原始文本内容
}
```

检索策略：

- 相似度计算：余弦相似度（ChromaDB 默认）
- 返回数量：默认 Top 5，可配置
- 过滤条件：支持按 metadata 过滤（文章、分类等）
- 排序：按相似度分数降序

---

## 性能优化

1. **批量索引**：支持批量索引所有已发布文章，自动跳过已索引的，单篇文章失败不影响其他文章
2. **增量更新**：检查是否已索引，避免重复处理，支持强制重新索引
3. **资源管理**：限流保护、超时控制、错误重试

## 故障处理

常见问题：

1. **Ollama 服务未启动**
   - 错误：`Ollama embedding 失败: 请确保 Ollama 服务已启动`
   - 解决：启动 Ollama 服务，检查端口 11434

2. **块超过 800 字符**
   - 警告：`块 X 被切分为 N 个子块`
   - 原因：分块逻辑可能有 bug
   - 解决：检查分块逻辑，确保严格控制大小

3. **ChromaDB 连接失败**
   - 错误：`Failed to initialize Chroma collection`
   - 解决：检查 ChromaDB 服务，检查端口 8000

4. **Token 估算偏差**
   - 现象：块大小控制不准确
   - 解决：双重检查字符数，确保不超过 800

建议监控：

- 索引成功率
- 平均块大小
- 子块生成频率
- embedding 生成耗时

## 总结

这个向量索引系统通过语义感知的智能分块、双重限制保护、多向量支持等特性，实现了高效的文档索引和检索。在保持语义完整性的同时，严格遵守 Ollama 的技术限制，确保系统稳定可靠。

核心优势：

- 语义完整性：按段落/句子分割，保持语义连贯
- 技术合规：严格遵守 Ollama 800 字符限制
- 信息保留：多向量支持，不丢失长文本信息
- 性能优化：重试、限流、超时控制
- 可扩展性：支持批量索引、增量更新
