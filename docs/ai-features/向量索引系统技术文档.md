# 向量索引系统技术文档

## 📋 目录

- [系统概述](#系统概述)
- [核心亮点](#核心亮点)
- [技术难点](#技术难点)
- [整体流程](#整体流程)
- [分块策略详解](#分块策略详解)
- [Embedding 生成策略](#embedding-生成策略)
- [向量存储与检索](#向量存储与检索)
- [性能优化](#性能优化)
- [故障处理](#故障处理)

---

## 系统概述

本系统实现了基于向量检索的 RAG（Retrieval-Augmented Generation）能力，支持对博客文章进行语义索引和智能检索。

### 技术栈

- **Embedding 模型**: Ollama (nomic-embed-text) - 本地免费运行
- **向量数据库**: ChromaDB - 开源向量数据库
- **分块策略**: 语义感知的智能分块
- **语言模型**: Kimi (Moonshot AI) - 用于生成和问答

### 架构图

```
文章内容
    ↓
[语义分块] chunkPost() - 按段落/句子智能分割
    ↓
[生成向量] ollamaEmbed() - 为每个块生成 embedding
    ↓
[存储向量] ChromaDB - 存储向量和元数据
    ↓
[检索查询] 根据用户问题找到最相关的块
    ↓
[生成回答] Kimi - 基于检索到的上下文生成回答
```

---

## 核心亮点

### 1. 🎯 语义感知的智能分块

**问题**: 简单的按字符数硬切会破坏语义完整性，导致：

- 句子被截断，丢失上下文
- 段落被分割，破坏逻辑连贯性
- 检索时匹配到不完整的语义片段

**解决方案**: 三级分块策略

1. **第一级：按段落分割** (`\n\n+`)
   - 保留文章的段落结构
   - 每个段落作为独立的语义单元

2. **第二级：按句子分割** (`。！？\n`)
   - 对于超长段落，按句子边界分割
   - 保留句子完整性

3. **第三级：严格控制大小**
   - 在语义分割的同时，严格控制块大小
   - 避免后续硬切破坏语义

**效果**:

- ✅ 保持语义完整性
- ✅ 避免句子/段落被截断
- ✅ 提高检索准确性

### 2. 🔄 重叠策略（Overlap）

**问题**: 相邻块之间没有重叠，可能导致：

- 跨块的信息丢失
- 检索时无法匹配到边界信息

**解决方案**:

- 默认重叠 50 字符
- 在保存当前块时，保留末尾的 overlap 字符
- 下一个块从 overlap 开始，确保上下文连贯

**效果**:

- ✅ 提高边界信息的检索率
- ✅ 保持块之间的上下文连贯性

### 3. 🛡️ 双重限制保护

**问题**: 仅按 token 数限制可能导致字符数超限（Ollama 硬限制 800 字符）

**解决方案**:

- **Token 限制**: 估算 token 数，控制语义长度（默认 300 tokens）
- **字符限制**: 硬限制字符数，遵守 Ollama 限制（800 字符）

**效果**:

- ✅ 同时满足语义和硬限制要求
- ✅ 避免 embedding 生成失败

### 4. 📊 多向量支持

**问题**: 如果某个块超过 800 字符，求平均会丢失信息

**解决方案**:

- 超过 800 字符的块会被硬切为多个子块
- 每个子块生成独立的 embedding 向量
- 每个子块单独存储，保持独立性

**效果**:

- ✅ 保留所有子块的语义信息
- ✅ 提高长文本的检索准确性

### 5. ⚡ 性能优化

- **批量处理**: 支持批量索引所有文章
- **重试机制**: Embedding 生成失败自动重试（最多 3 次）
- **限流保护**: 每处理 5 个块后等待 100ms，避免 Ollama 过载
- **超时控制**: 30 秒超时，避免长时间等待

---

## 技术难点

### 难点 1: 语义分块 vs 硬限制的平衡

**挑战**:

- 语义分块希望保持完整性，可能产生较大的块
- Ollama 硬限制 800 字符，必须遵守

**解决方案**:

1. 在语义分块阶段就严格控制大小
2. 优先按段落/句子分割，保持语义完整性
3. 仅在无法按语义分割时，才进行硬切（最后手段）

**代码实现**:

```typescript
// 双重检查：既检查 token 数，也检查字符数
const chunkTokens = estimateTokens(currentChunk);
const chunkChars = currentChunk.length;

if (chunkTokens > maxTokens || chunkChars > maxChars) {
  // 需要进一步分割
  splitChunk(currentChunk);
}
```

### 难点 2: 长文本的向量生成策略

**挑战**:

- 如果块超过 800 字符，Ollama 无法处理
- 求平均会丢失子块之间的顺序和位置信息

**解决方案**:

- 硬切为多个子块（保留重叠）
- 每个子块生成独立的 embedding
- 每个子块单独存储，通过 metadata 关联

**代码实现**:

```typescript
// 如果超过 800 字符，返回多个向量
if (t.length > MAX_CHUNK_SIZE) {
  const chunks = hardSplit(t);
  for (const chunk of chunks) {
    const embedding = await getEmbedding(chunk);
    embeddings.push(embedding); // 返回多个向量
  }
}
```

### 难点 3: Token 估算的准确性

**挑战**:

- 中英文混合文本的 token 估算不准确
- 估算偏差可能导致块大小控制失效

**解决方案**:

- 中文按字符数估算（1 字符 ≈ 1.5 tokens）
- 英文按单词数估算（1 单词 ≈ 1.3 tokens）
- 允许 20% 的误差范围，双重检查字符数

**代码实现**:

```typescript
function estimateTokens(text: string): number {
  const chineseChars = (text.match(/[\u4e00-\u9fa5]/g) || []).length;
  const englishWords = text
    .split(/\s+/)
    .filter((w) => /[a-zA-Z]/.test(w)).length;
  return Math.ceil(chineseChars * 1.5 + englishWords * 1.3);
}
```

### 难点 4: 子块的管理和检索

**挑战**:

- 一个语义块可能对应多个向量（子块）
- 需要正确关联和检索

**解决方案**:

- 使用 `chunkIndex_subChunkIndex` 作为向量 ID
- 在 metadata 中标记 `isSubChunk: true`
- 检索时可以通过 `chunkIndex` 关联所有子块

**代码实现**:

```typescript
// 为子块创建向量记录
vectors.push({
  id: `${postId}_${chunk.index}_${j}`,
  embedding: chunkEmbeddings[j],
  metadata: {
    chunkIndex: chunk.index,
    subChunkIndex: j,
    isSubChunk: true,
    // ...
  },
});
```

---

## 整体流程

### 索引流程（Indexing）

```
1. 获取文章
   ↓
2. 检查是否已索引（避免重复索引）
   ↓
3. 语义分块 (chunkPost)
   - 按段落分割
   - 按句子分割（如需要）
   - 严格控制大小（≤800字符）
   ↓
4. 生成 Embedding (ollamaEmbed)
   - 为每个块生成向量
   - 如果块超过800字符，生成多个向量
   - 重试机制（最多3次）
   ↓
5. 构建向量数据
   - 为每个向量创建 metadata
   - 包含文章信息、块索引等
   ↓
6. 存储到 ChromaDB
   - 向量 + 元数据 + 原文
   ↓
7. 更新索引记录
   - 记录文章ID、块数量等
```

### 检索流程（Retrieval）

```
1. 用户提问
   ↓
2. 生成查询向量 (embed(question))
   ↓
3. 向量相似度搜索 (ChromaDB)
   - 找到最相关的 K 个块
   - 返回相似度分数
   ↓
4. 过滤和排序
   - 按相似度排序
   - 可选：按文章、分类过滤
   ↓
5. 构建上下文
   - 组合多个相关块
   - 添加文章元数据
   ↓
6. 生成回答 (Kimi)
   - 基于检索到的上下文
   - 流式返回结果
```

---

## 分块策略详解

### 分块流程

```typescript
文章内容
    ↓
按段落分割 (\n\n+)
    ↓
遍历每个段落
    ├─ 段落 ≤ 限制？
    │   ├─ 是 → 加入当前块
    │   └─ 否 → 分割段落
    │       ├─ 按句子分割 (。！？\n)
    │       └─ 控制句子块大小
    └─ 当前块超过限制？
        └─ 是 → 保存当前块，保留重叠
```

### 关键参数

| 参数        | 默认值 | 说明                        |
| ----------- | ------ | --------------------------- |
| `maxTokens` | 300    | Token 数限制（语义控制）    |
| `maxChars`  | 800    | 字符数硬限制（Ollama 限制） |
| `overlap`   | 50     | 块之间的重叠字符数          |

### 分块示例

**输入文章**:

```
段落1：这是第一段内容，包含多个句子。每个句子都有意义。

段落2：这是第二段，内容较长。包含很多信息。需要仔细处理。确保完整性。

段落3：短段落。
```

**分块结果**:

```
块0: "段落1：这是第一段内容，包含多个句子。每个句子都有意义。"
块1: "段落2：这是第二段，内容较长。包含很多信息。需要仔细处理。确保完整性。"
块2: "段落3：短段落。"
```

---

## Embedding 生成策略

### 处理逻辑

```typescript
输入文本块
    ↓
检查长度
    ├─ ≤ 800 字符 → 直接生成 embedding
    └─ > 800 字符 → 硬切分块
        ├─ 子块1 → embedding1
        ├─ 子块2 → embedding2
        └─ 子块N → embeddingN
            ↓
        返回多个向量
```

### 重试机制

- **最大重试次数**: 3 次
- **重试间隔**: 1 秒
- **超时时间**: 30 秒
- **失败处理**: 抛出错误，记录日志

### 性能优化

- **限流**: 每处理 5 个块后等待 100ms
- **并发控制**: 串行处理，避免 Ollama 过载
- **错误恢复**: 自动重试，提高成功率

---

## 向量存储与检索

### 向量数据结构

```typescript
{
  id: "postId_chunkIndex" | "postId_chunkIndex_subChunkIndex",
  embedding: number[], // 768 维向量（nomic-embed-text）
  metadata: {
    postId: string,
    chunkIndex: number,
    subChunkIndex?: number, // 仅子块有
    isSubChunk?: boolean,   // 仅子块有
    title: string,
    slug: string,
    category: string,
    tags: string,
  },
  document: string, // 原始文本内容
}
```

### 检索策略

1. **相似度计算**: 余弦相似度（ChromaDB 默认）
2. **返回数量**: 默认 Top 5，可配置
3. **过滤条件**: 支持按 metadata 过滤（文章、分类等）
4. **排序**: 按相似度分数降序

---

## 性能优化

### 1. 批量索引

- 支持批量索引所有已发布文章
- 自动跳过已索引的文章
- 错误隔离：单篇文章失败不影响其他文章

### 2. 增量更新

- 检查是否已索引，避免重复处理
- 支持强制重新索引（`force: true`）
- 更新索引记录的时间戳

### 3. 资源管理

- 限流保护：避免 Ollama 过载
- 超时控制：避免长时间等待
- 错误重试：提高成功率

---

## 故障处理

### 常见问题

1. **Ollama 服务未启动**
   - 错误: `Ollama embedding 失败: 请确保 Ollama 服务已启动`
   - 解决: 启动 Ollama 服务，检查端口 11434

2. **块超过 800 字符**
   - 警告: `块 X 被切分为 N 个子块`
   - 原因: chunkPost 分块逻辑可能有 bug
   - 解决: 检查分块逻辑，确保严格控制大小

3. **ChromaDB 连接失败**
   - 错误: `Failed to initialize Chroma collection`
   - 解决: 检查 ChromaDB 服务，检查端口 8000

4. **Token 估算偏差**
   - 现象: 块大小控制不准确
   - 解决: 双重检查字符数，确保不超过 800

### 监控建议

- 记录索引成功率
- 监控平均块大小
- 跟踪子块生成频率
- 记录 embedding 生成耗时

---

## 总结

本向量索引系统通过**语义感知的智能分块**、**双重限制保护**、**多向量支持**等核心特性，实现了高效、准确的文档索引和检索能力。系统在保持语义完整性的同时，严格遵守 Ollama 的技术限制，确保了系统的稳定性和可靠性。

### 核心优势

✅ **语义完整性**: 按段落/句子分割，保持语义连贯  
✅ **技术合规**: 严格遵守 Ollama 800 字符限制  
✅ **信息保留**: 多向量支持，不丢失长文本信息  
✅ **性能优化**: 重试、限流、超时控制  
✅ **可扩展性**: 支持批量索引、增量更新

---

**最后更新**: 2025-01-XX  
**维护者**: 开发团队
