---
title: AI基础知识全面解析：从LLM到AGI的技术演进之路
cacategory: AI
published: true
featured: false
readingTime: 1
---

# AI基础知识全面解析：从LLM到AGI的技术演进之路

## 背景介绍

AI（ChatGPT）已经充斥了我们的生活和工作，但是很多基本概念亟待我们了解和学习。下面分别对LLM、Prompt、Fine-tuning、Vector database、RAG，Agent， AGI等进行简单的介绍。

## 1. 什么是大模型（LLM）

大模型是指具有大规模参数和复杂计算结构的机器学习模型。

大模型就像是一个超级"大脑"，它不是一台普通计算机而是通过学习海量信息后能够完成各种复杂任务的智能系统。

### 1.1 大模型的特点

![大模型特点](/images/ai-base/image.png)

### 1.2 大模型的分类

1. **语言大模型**：专注于理解和生成人类语言的模型
2. **视觉大模型**：专注于处理图像和视频的模型，能够识别物体、场景和行为等
3. **多模态大模型**：能同时理解文字、图像、声音等多种信息的模型

## 2. 提示词工程（Prompt Engineering）

提示词就是给大模型输入的文字。

![提示词工程](/images/ai-base/image%20copy.png)

提示词工程不仅仅是简单的提问，而是一门能让AI更好理解和执行我们需求的技术。

**Prompt技巧：**

- **结构化Prompt**：角色 + 任务 + 要求 + 细节【步骤拆解、范例说明，技巧点拨等】
- **链式prompt**：拆分长Prompt，多提示词协同

提示词看起来很简单，给出一句话，大模型就会给出问题响应，但要想大模型精准回复问题，是自己想要的答案，还需要有结构化的提示词知识。

**省流**：说清楚你要干什么，不要让大模型去猜你的意思。

## 3. 微调（Fine-tuning）

### 3.1 什么是微调（Fine-tuning）

Fine-tuning（微调）：通过特定领域数据对大模型进行针对性优化，以提升其在特定任务上的性能。

大模型微调是提升AI应用性能的有效手段，主要基于以下几点考虑：

1. 大模型参数众多，训练成本高，不适宜每家公司都从头开始训练
2. 当Prompt效果不佳，而企业又拥有高质量的自有数据时，微调可以显著提升模型在特定领域的性能
3. 微调支持个性化服务。企业可以针对每个用户的数据训练轻量级的微调模型，提供定制化服务
4. 数据安全也是微调的重要原因。对于不能共享给第三方的数据，企业需要自行微调开源大模型

### 3.2 如何微调（Fine-tuning）

在参数规模上，大模型微调主要有两种方法：全量微调（FFT）和参数高效微调（PEFT）。

![微调方法](/images/ai-base/image%20copy%202.png)

**模型微调流程：**

1. **选择与任务相关的数据集**：对数据进行预处理（数据清洗、分词处理、数据编码等）
2. **选择基础模型**：选择预训练好的大语言模型(如 DeepSeek 等)
3. **设置微调参数**：合理的参数设置能够提升训练效果
4. **具体的模型微调执行步骤**：加载预训练模型和权重→ 根据任务需求修改模型结构→ 选择损失函数和优化器→ 执行微调训练（前向传播、损失计算、反向传播、权重更新等）

## 4. 向量数据库（Vector database）

在AI的机器学习和深度学习中，数据通常以向量形式存在于向量数据库中。

### 4.1 什么是向量？

在前端中，任何一种颜色都可以通过RGB三种颜色的组合来得到，这就是一个非常经典的向量表示案例。

### 4.2 常见的数据库类型

![数据库类型](/images/ai-base/image%20copy%203.png)

1. **关系型数据库**是最基础的数据库类型，其表现特征为二维表格，行和列清晰分明
2. **KV数据库**以键值对的形式存储数据，且value可以是多种类型，如字符串、数字或二进制等
3. **文档型数据库**（如MongoDB）是通过一对一的映射关系来存储数据
4. **图数据库**以网状结构呈现数据，特别适合处理复杂的关系网络
5. **向量数据库**支持多维向量数据存储，在向量数据库中，数据可以映射到多维坐标系统中的点
6. **分析型数据库**（即OLAP数据库）通常采用列式存储，是在实际应用中使用较多的一类数据库

### 4.3 向量数据库的特点及应用

- **特点**：向量数据库凭借高效存储、索引和搜索高维数据点的能力，更擅长处理非结构化数据，在处理比如：数值特征、文本或图像嵌入等复杂数据时表现出色
- **Embedding**：在人工智能领域，将词汇、文本、语句、段落、图片或音频等对象转换为数学向量，被称为嵌入（Embedding）
- 人工智能大模型的"思考"过程，本质上是一系列涉及向量和矩阵的数学运算

#### 4.3.1 一个图像识别的基本案例：

1. 假设我们有一万张图片，通过embedding算法将每张图片转换成向量，并存入向量数据库
2. 搜索时，先用embedding模型将目标图片转为向量，在数据库中检索相似度高的图片
3. 返回这些相似度图片的ID、路径和相似度距离

![图像识别案例](/images/ai-base/image%20copy%204.png)

#### 4.3.2 Cursor Codebase Indexing

![Cursor代码库索引](/images/ai-base/image%20copy%205.png)

Cursor 的代码库索引功能通过以下关键步骤实现：

1. **文件扫描与预处理**：遍历项目目录，读取并预处理所有代码文件
2. **文本分块**：将文件拆分为具有语义连贯性的代码块，便于后续处理
3. **嵌入生成**：利用专门的嵌入模型将每个代码块转换为向量表示，捕捉代码的语义信息
4. **向量索引构建**：将所有嵌入存入支持高效近似最近邻搜索的索引库，并关联元数据
5. **在线查询与检索**：将用户查询文本嵌入后，在索引库中搜索最相似的代码块，并整合反馈给 AI 语言模型
6. **实时更新与缓存**：通过文件监控机制和缓存策略，确保索引库与实际代码保持同步，提高查询响应速度

## 5. 检索增强生成（RAG）

### 5.1 什么是RAG

RAG （Retrieval-Augmented Generation）检索增强生成，是一种通过整合外部知识库来增强大模型（LLM）的性能的模式。

最简单的理解，可以认为是给大模型外挂了一个知识库。

RAG具有较强的可解释性和定制能力，适用于问答系统、文档生成、智能助手等多个自然语言处理任务中。RAG模型的优势在于通用性强、可实现即时的知识更新，以及通过端到端评估方法提供更高效和精准的信息服务。

### 5.2 为什么要用 RAG

因为大模型（LLM）的知识存在固有缺陷：

1. **知识不新**：由于训练的时间和成本，大模型的知识往往是旧的
2. **知识不全**：缺少专业的领域知识或私有的业务知识

### 5.3 RAG架构

RAG = LLM+知识库

RAG的工作原理是通过检索大规模文档集合中的相关信息，然后利用这些信息来指导文本的生成，从而提高预测的质量和准确性。

![RAG架构图1](/images/ai-base/image%20copy%206.png)

具体而言，RAG通过三个关键部分实现工作：检索、利用和生成。在检索阶段，系统会从文档集合中检索相关信息；在利用阶段，系统会利用这些检索到的信息来填充文本或回答问题；最后在生成阶段，系统会根据检索到的知识来生成最终的文本内容。

![RAG架构图2](/images/ai-base/image%20copy%207.png)

通过这一过程，RAG模型能够在各种自然语言处理任务中发挥作用，如问答系统、文档生成和自动摘要、智能助手和虚拟代理、信息检索以及知识图谱填充等。同时，RAG模型具有及时更新、解释性强、高度定制能力、安全隐私管理以及减少训练成本等优点。与微调相比，RAG是通用的，适用于多种任务，并且能够实现即时的知识更新而无需重新训练模型。

### 5.4 知识库介绍

对于企业而言，构建一个符合自身业务需求的知识库是至关重要的。通过RAG、微调等技术手段，我们可以将通用的大模型转变为对特定行业有着深度理解的"行业专家"。

#### 5.4.1 知识库的技术架构

**第一、离线的知识数据向量化**

1. **加载**：通过文档加载器（Document Loaders）加载数据/知识库
2. **拆分**：文本拆分器将大型文档拆分为较小的块。便于向量或和后续检索
3. **向量**：对拆分的数据块，进行 Embedding （Embedding 是一种将高维数据（如单词、句子、图片等）转换为低维向量空间的技术。这个过程的目的是使数据在低维空间中以一种更易于计算和处理的方式表示，同时尽可能保留数据之间的语义关系）向量化处理
4. **存储**：将向量化的数据块存储到向量数据库 VectorDB 中，方便进行搜索

![知识库技术架构](/images/ai-base/image%20copy%208.png)

**第二、在线的知识检索返回**

1. **检索**：根据用户输入，使用检索器从存储中检索相关的 Chunk
2. **生成**：使用包含问题和检索到的知识提示词，交给大语言模型生成答案

![知识检索返回](/images/ai-base/image%20copy%209.png)

## 6. 智能体（AI Agent）

Agent = LLM+Planning+Tool use+Feedback

Agent 是让 LLM 具备目标实现的能力，并通过自我激励循环来实现这个目标。

### 6.1 Copilot、workflow和Agent的三者区别

- **Copilot**：英文释义为"副驾驶"，在编程中可理解为代码提示辅助工具
- **Workflow**：是对工作流程及其各操作步骤之间业务规则的抽象、概括描述，简称工作流
- **Agent**：是指能够自主感知环境、做出决策并采取行动的计算实体

Workflow和Agent的关键区别在于自主决策能力，

简单说 Workflow 就像是固定的生产线，每个步骤都是预先设计好的；
而 Agent 则像是有自主思考能力的助手，通过感知-决策-执行的路径，可以自己决定怎么做、做多久。

**想象一下厨房里做菜的三种场景：**

- **Copilot**：像是旁边一直出主意的助手，看你切菜会提醒"这样切更好"，炒菜时会建议"该放调料了"，但不会自己动手
- **Workflow**：按照菜谱一步步做菜，第一步切菜，第二步放油，第三步炒菜，每一步都是预先定好的，按部就班地执行，过程中如果出现没油了，可能炒菜就得中断了
- **Agent**：你告诉一个会做饭的人"做一道可口的晚餐"，他会根据冰箱里有什么材料，自己决定做什么菜，如何烹饪，需要走多少步骤才能完成，如果没油了，Agent 会自己知道要去买油

AI Agent是由人工智能驱动的程序，当给定目标时，它们能够自己创建任务、完成任务、创建新任务、重新确定任务列表的优先级、完成新的顶级任务，并循环直到达到目标。

### 6.2 PDCA思维模型

我们可以把智能体执行过程比作PDCA思维模型，我们可以将完成一项任务进行拆解，按照作出计划、计划实施、检查实施效果，然后将成功的纳入标准，不成功的留待下一循环去解决。

![PDCA思维模型](/images/ai-base/image%20copy%2010.png)

### 6.3 智能体架构

PDCA 循环是人日常做事思维模型，大模型是否可以像人一样，让大模型代替人的工作。

因而，智能体应运而生，让大模型具备执行能力，基于PDCA模型进行规划、执行、评估和反思。

![智能体架构](/images/ai-base/image%20copy%2011.png)

**规划能力（Plan）**：智能体（Agent）的大脑能够将复杂的大任务细分为小的、可操作的子任务，这种能力对于高效、有序地处理大型任务至关重要。

**执行能力（Do）**：智能体能学会在内部知识不足时调用外部API，例如获取实时信息、执行代码或访问专有知识库。这需要构建一个平台加工具的生态系统，鼓励其他厂商提供更多工具组件，共同形成繁荣的生态系统。

**评估能力（Check）**：任务执行后，智能体需要判断结果是否达到预期目标，并在出现异常时进行分类、定位和原因分析。这种能力通常不是通用大模型所具备的，需要针对特定场景进行定制化的小模型训练。

**反思能力（Action）**：基于评估结果，智能体能够及时结束任务或进行归因分析，总结成功的关键因素。如果出现异常或结果不符合目标，智能体会提出应对策略，重新规划并启动新的循环过程，这是整个任务管理流程的核心部分。

### 6.4 智能体框架

智能体是当前大模型最火热的话题，当下主流的智能体开发框架有manus、秒哒。

![智能体框架](/images/ai-base/image%20copy%2012.png)

**虚拟机**：一个 Linux 系统的虚拟机，安装有

1. Chrome 浏览器，用来访问网页
2. Python 运行环境，可以执行脚本分析数据，可以启动一个网页运行环境

**任务规划器**：根据用户输入的任务请求，拆分成 ToDo List

**任务执行调度器**：根据 ToDo List 的任务清单，逐一执行，根据任务去选择最合适的 Agent

**各种执行不同类型任务的 Agents**：Manus 内置了很多 Agent，比如最复杂的应该是类似于 OpenAI Operator 的网页浏览 Agent，比如根据特定 API 检索特定数据的 Agent，每个 Agent 在完成任务后都会把任务结果写到虚拟机

**任务汇总生成器**：当每个子任务执行完成后，任务执行调度器就会通知任务汇总生成器，任务汇总生成器就会去虚拟机读取 ToDo List 以及各个子任务的生成结果，把这些结果汇总整理生成最终结果

## 7. 通用人工智能（AGI）

AGI即通用人工智能（Artificial General Intelligence）。通用人工智能是具备与人类同等智能、或超越人类的人工智能，能表现正常人类所具有的所有智能行为。旨在创造能够理解并处理各类复杂任务的智能系统，与人类智能相匹敌。

在通往这一宏伟目标的征途上，一系列关键技术发挥着不可或缺的作用：

- **AI大模型**通过其庞大的数据和模型参数，为理解和生成语言提供了基础
- **Prompt Engineering**引导AI模型产生准确的响应
- **知识库和向量数据库**则为AI提供了丰富的信息资源和高效的数据检索能力
- **RAG（Retrieval-Augmented Generation）**模型结合了检索和生成，进一步提升了AI处理任务的灵活性和准确性
- **Agent智能体技术**赋予了AI自主行动和决策的能力

这些技术相互配合，形成了一个多元化、高度协作的AI生态系统。它们共同推动着AI技术的持续进步，为实现AGI的终极目标打下了坚实的基础。

## 总结

本文全面介绍了AI领域的核心技术概念，从基础的大模型（LLM）到前沿的通用人工智能（AGI），构建了一个完整的AI技术知识体系。这些技术不仅各自具有独特的价值，更在相互结合中展现出强大的协同效应，共同推动着AI技术向更高层次发展。

对于AI学习者和从业者来说，深入理解这些基础概念是掌握AI技术的重要前提。随着技术的不断发展，这些概念也将持续演进，值得我们持续关注和学习。
